{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries for webscraping\n",
    "\n",
    "import requests     # Pull raw HTML from site\n",
    "from bs4 import BeautifulSoup     # Parsing library that pulls data from HTML/XML code\n",
    "from lxml import html     # High-speed parsing library used with BeautifulSoup\n",
    "\n",
    "\n",
    "# Import library to set up and work in DataFrame\n",
    "import numpy as np     # Scientific computing\n",
    "import pandas as pd     # Build out DataFrame\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Import libraries for plotting and visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import regex as re\n",
    "import pickle\n",
    "\n",
    "sns.set_style(\"whitegrid\")     # Control the appearances of the plots\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize search parameters and dataframe\n",
    "# 'my',\n",
    "country_set = ['sg']\n",
    "search_string = ['data analyst']\n",
    "columns = [\"job_category\",\"job_title\", \"company_name\", \"location\", \"summary\", \"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com.sg/jobs?q=data+analyst&start=\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 728 entries, 0 to 727\n",
      "Data columns (total 6 columns):\n",
      "job_category    728 non-null object\n",
      "job_title       728 non-null object\n",
      "company_name    712 non-null object\n",
      "location        720 non-null object\n",
      "summary         728 non-null object\n",
      "salary          29 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 34.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Initialize container to store all job postings\n",
    "jobs_list = []\n",
    "\n",
    "# Iterate through search parameters and store relevant data in respective columns in dataframe\n",
    "for country in country_set:\n",
    "    for query in search_string:\n",
    "        \n",
    "        url = 'https://www.indeed.com.' + country + '/jobs?q=' + '+'.join([word for word in query.split()]) + '&start='\n",
    "        print(url)\n",
    "        time.sleep(1)\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "        jobs_count = soup.find_all('div', {'id':'searchCount'})[0].get_text()\n",
    "\n",
    "        # Get maximum number of jobs to iterate over all pages\n",
    "#         max_jobs = int(re.sub('[^0-9a-zA-Z]+', '', jobs_count.split()[-1]))\n",
    "        max_jobs = int(jobs_count.replace(' Page 1 of ', '').replace('jobs', '').replace(',', ''))\n",
    "\n",
    "        for start_number in range(0,max_jobs,10):\n",
    "            time.sleep(1)\n",
    "            url_page = url + str(start_number)\n",
    "            page = requests.get(url_page)\n",
    "            soup = BeautifulSoup(page.text, 'lxml')\n",
    "            \n",
    "            # Get all advertised job descriptions\n",
    "            regex = re.compile('.*row.*')\n",
    "            jobs = soup.find_all(name='div', attrs={'class':regex})\n",
    "            \n",
    "            # Get job title from job description\n",
    "            for job in jobs:\n",
    "                job_title = job.find(name='a', attrs={'data-tn-element':'jobTitle'})\n",
    "                company = job.find(name='span', attrs={'class':'company'})\n",
    "                location = job.find(name='span', attrs={'class':'location'})\n",
    "                summary = job.find(name='span', attrs={'class':'summary'})\n",
    "                salary = job.find(name='span', attrs={'class':'no-wrap'})\n",
    "\n",
    "                # Put default for missing variables\n",
    "                if job_title != None:\n",
    "                    job_title_result = job_title.get_text()\n",
    "                    job_title_result = job_title_result.replace('\\n','')\n",
    "                    job_title_result = job_title_result.strip()\n",
    "                else:\n",
    "                    job_title_result = np.nan\n",
    "\n",
    "                if company != None:\n",
    "                    company_result = company.get_text()\n",
    "                    company_result = company_result.replace('\\n','')\n",
    "                    company_result = company_result.strip()\n",
    "                else:\n",
    "                    company_result = np.nan\n",
    "\n",
    "                if location != None:\n",
    "                    location_result = location.get_text()\n",
    "                    location_result = location_result.replace('\\n','')\n",
    "                    location_result = location_result.strip()\n",
    "                else:\n",
    "                    location_result = np.nan\n",
    "\n",
    "                if summary != None:\n",
    "                    summary_result = summary.get_text()\n",
    "                    summary_result = summary_result.replace('\\n','')\n",
    "                    summary_result = summary_result.strip()\n",
    "                else:\n",
    "                    summary_result = np.nan\n",
    "\n",
    "                if salary != None:\n",
    "\n",
    "                    salary_result = salary.get_text()\n",
    "                    salary_result = salary_result.replace('\\n','')\n",
    "                    salary_result = salary_result.strip()\n",
    "                else:\n",
    "                    salary_result = np.nan\n",
    "\n",
    "                # Append to list\n",
    "                job_category = '_'.join([word for word in query.split()])\n",
    "                jobs_list.append([job_category,job_title_result, company_result, location_result, summary_result, salary_result])\n",
    "\n",
    "# Convert jobs list to dataframe\n",
    "df = pd.DataFrame(jobs_list, columns = columns)\n",
    "# drop all duplicated job postings based on summary\n",
    "df.drop_duplicates(subset=['summary'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"DA_Search\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
