{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Project 4: Web Scraping Job Postings\n",
    "\n",
    "## Business Case Overview\n",
    "\n",
    "You're working as a data scientist for a contracting firm that's rapidly expanding. Now that they have their most valuable employee (you!), they need to leverage data to win more contracts. Your firm offers technology and scientific solutions and wants to be competitive in the hiring market. Your principal has two main objectives:\n",
    "\n",
    "   1. Determine the industry factors that are most important in predicting the salary amounts for these data.\n",
    "   2. Determine the factors that distinguish job categories and titles from each other. For example, can required skills accurately predict job title?\n",
    "\n",
    "To limit the scope, your principal has suggested that you *focus on data-related job postings*, e.g. data scientist, data analyst, research scientist, business intelligence, and any others you might think of. You may also want to decrease the scope by *limiting your search to a single region.*\n",
    "\n",
    "Hint: Aggregators like [Indeed.com](https://www.indeed.com) regularly pool job postings from a variety of markets and industries. \n",
    "\n",
    "**Goal:** Scrape your own data from a job aggregation tool like Indeed.com in order to collect the data to best answer these two questions.\n",
    "\n",
    "---\n",
    "\n",
    "## Directions\n",
    "\n",
    "In this project you will be leveraging a variety of skills. The first will be to use the web-scraping and/or API techniques you've learned to collect data on data jobs from Indeed.com or another aggregator. Once you have collected and cleaned the data, you will use it to answer the two questions described above.\n",
    "\n",
    "### QUESTION 1: Factors that impact salary\n",
    "\n",
    "To predict salary you will be building either a classification or regression model, using features like the location, title, and summary of the job. If framing this as a regression problem, you will be estimating the listed salary amounts. You may instead choose to frame this as a classification problem, in which case you will create labels from these salaries (high vs. low salary, for example) according to thresholds (such as median salary).\n",
    "\n",
    "You have learned a variety of new skills and models that may be useful for this problem:\n",
    "- NLP\n",
    "- Unsupervised learning and dimensionality reduction techniques (PCA, clustering)\n",
    "- Ensemble methods and decision tree models\n",
    "- SVM models\n",
    "\n",
    "Whatever you decide to use, the most important thing is to justify your choices and interpret your results. *Communication of your process is key.* Note that most listings **DO NOT** come with salary information. You'll need to able to extrapolate or predict the expected salaries for these listings.\n",
    "\n",
    "### QUESTION 2: Factors that distinguish job category\n",
    "\n",
    "Using the job postings you scraped for part 1 (or potentially new job postings from a second round of scraping), identify features in the data related to job postings that can distinguish job titles from each other. There are a variety of interesting ways you can frame the target variable, for example:\n",
    "- What components of a job posting distinguish data scientists from other data jobs?\n",
    "- What features are important for distinguishing junior vs. senior positions?\n",
    "- Do the requirements for titles vary significantly with industry (e.g. healthcare vs. government)?\n",
    "\n",
    "You may end up making multiple classification models to tackle different questions. Be sure to clearly explain your hypotheses and framing, any feature engineering, and what your target variables are. The type of classification model you choose is up to you. Be sure to interpret your results and evaluate your models' performance.\n",
    "\n",
    "\n",
    "### BONUS PROBLEM\n",
    "\n",
    "Your boss would rather tell a client incorrectly that they would get a lower salary job than tell a client incorrectly that they would get a high salary job. Adjust one of your models to ease his mind, and explain what it is doing and any tradeoffs. Plot the ROC curve.\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements\n",
    "\n",
    "1. Scrape and prepare your own data.\n",
    "\n",
    "2. **Create and compare at least two models for each section**. One of the two models should be a decision tree or ensemble model. The other can be a classifier or regression of your choosing (e.g. Ridge, logistic regression, KNN, SVM, etc).\n",
    "   - Section 1: Job Salary Trends\n",
    "   - Section 2: Job Category Factors\n",
    "\n",
    "3. Prepare a polished Jupyter Notebook with your analysis for a peer audience of data scientists. \n",
    "   - Make sure to clearly describe and label each section.\n",
    "   - Comment on your code so that others could, in theory, replicate your work.\n",
    "\n",
    "4. A brief writeup in an executive summary, written for a non-technical audience.\n",
    "   - Writeups should be at least 500-1000 words, defining any technical terms, explaining your approach, as well as any risks and limitations.\n",
    "\n",
    "#### BONUS\n",
    "\n",
    "5. Answer the salary discussion by using your model to explain the tradeoffs between detecting high vs low salary positions.\n",
    "\n",
    "6. Convert your executive summary into a public blog post of at least 500 words, in which you document your approach in a tutorial for other aspiring data scientists. Link to this in your notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## Suggestions for Getting Started\n",
    "\n",
    "1. Collect data from [Indeed.com](www.indeed.com) (or another aggregator) on data-related jobs to use in predicting salary trends for your analysis.\n",
    "  - Select and parse data from *at least 1000 postings* for jobs, potentially from multiple location searches.\n",
    "2. Find out what factors most directly impact salaries (e.g. title, location, department, etc).\n",
    "  - Test, validate, and describe your models. What factors predict salary category? How do your models perform?\n",
    "3. Discover which features have the greatest importance when determining a low vs. high paying job.\n",
    "  - Your Boss is interested in what overall features hold the greatest significance.\n",
    "  - HR is interested in which SKILLS and KEY WORDS hold the greatest significance.   \n",
    "4. Author an executive summary that details the highlights of your analysis for a non-technical audience.\n",
    "5. If tackling the bonus question, try framing the salary problem as a classification problem detecting low vs. high salary positions.\n",
    "\n",
    "---\n",
    "\n",
    "## Useful Resources\n",
    "\n",
    "- Scraping is one of the most fun, useful and interesting skills out there. Don’t lose out by copying someone else's code!\n",
    "- [Here is some advice on how to write for a non-technical audience](http://programmers.stackexchange.com/questions/11523/explaining-technical-things-to-non-technical-people)\n",
    "- [Documentation for BeautifulSoup can be found here](http://www.crummy.com/software/BeautifulSoup/).\n",
    "\n",
    "---\n",
    "\n",
    "### Project Feedback + Evaluation\n",
    "\n",
    "For all projects, students will be evaluated on a simple 3 point scale (0, 1, or 2). Instructors will use this rubric when scoring student performance on each of the core project **requirements:** \n",
    "\n",
    "Score | Expectations\n",
    "----- | ------------\n",
    "**0** | _Does not meet expectations. Try again._\n",
    "**1** | _Meets expectations. Good job._\n",
    "**2** | _Surpasses expectations. Brilliant!_\n",
    "\n",
    "[For more information on how we grade our DSI projects, see our project grading walkthrough.](https://git.generalassemb.ly/dsi-projects/readme/blob/master/README.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries for webscraping\n",
    "\n",
    "import requests     # Pull raw HTML from site\n",
    "from bs4 import BeautifulSoup     # Parsing library that pulls data from HTML/XML code\n",
    "from lxml import html     # High-speed parsing library used with BeautifulSoup\n",
    "\n",
    "\n",
    "# Import library to set up and work in DataFrame\n",
    "import numpy as np     # Scientific computing\n",
    "import pandas as pd     # Build out DataFrame\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Import libraries for plotting and visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import regex as re\n",
    "import pickle # Haven't figured how to use some of these yet\n",
    "\n",
    "sns.set_style(\"whitegrid\")     # Control the appearances of the plots\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize search parameters and dataframe\n",
    "# 'my',\n",
    "country_set = ['sg']\n",
    "search_string = ['data scientist', 'data analyst', 'business analyst']\n",
    "columns = [\"job_category\",\"job_title\", \"company_name\", \"location\", \"summary\", \"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com.sg/jobs?q=data+scientist&start=\n"
     ]
    },
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='www.indeed.com.sg', port=443): Max retries exceeded with url: /jobs?q=data+scientist&start=250 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(10060, 'WSAETIMEDOUT')\")))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSysCallError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 \u001b[0mcnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1906\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_do_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1907\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[1;34m(self, ssl, result)\u001b[0m\n\u001b[0;32m   1630\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0merrno\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mSysCallError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSysCallError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Unexpected EOF\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSysCallError\u001b[0m: (10060, 'WSAETIMEDOUT')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             ssl_context=context)\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad handshake: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLError\u001b[0m: (\"bad handshake: SysCallError(10060, 'WSAETIMEDOUT')\",)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 638\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.indeed.com.sg', port=443): Max retries exceeded with url: /jobs?q=data+scientist&start=250 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(10060, 'WSAETIMEDOUT')\")))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-000bcd4edc55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0murl_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m                 \u001b[1;31m# This branch is for urllib3 v1.22 and later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='www.indeed.com.sg', port=443): Max retries exceeded with url: /jobs?q=data+scientist&start=250 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(10060, 'WSAETIMEDOUT')\")))"
     ]
    }
   ],
   "source": [
    "# Initialize container to store all job postings\n",
    "jobs_list = []\n",
    "\n",
    "# Iterate through search parameters and store relevant data in respective columns in dataframe\n",
    "for country in country_set:\n",
    "    for query in search_string:\n",
    "        \n",
    "        url = 'https://www.indeed.com.' + country + '/jobs?q=' + '+'.join([word for word in query.split()]) + '&start='\n",
    "        print(url)\n",
    "        time.sleep(1)\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "        jobs_count = soup.find_all('div', {'id':'searchCount'})[0].get_text()\n",
    "\n",
    "        # Get maximum number of jobs to iterate over all pages\n",
    "#         max_jobs = int(re.sub('[^0-9a-zA-Z]+', '', jobs_count.split()[-1]))\n",
    "        max_jobs = int(jobs_count.replace(' Page 1 of ', '').replace('jobs', '').replace(',', ''))\n",
    "\n",
    "        for start_number in range(0,max_jobs,10):\n",
    "            time.sleep(1)\n",
    "            url_page = url + str(start_number)\n",
    "            page = requests.get(url_page)\n",
    "            soup = BeautifulSoup(page.text, 'lxml')\n",
    "            \n",
    "            # Get all advertised job descriptions\n",
    "            regex = re.compile('.*row.*')\n",
    "            jobs = soup.find_all(name='div', attrs={'class':regex})\n",
    "            \n",
    "            # Get job title from job description\n",
    "            for job in jobs:\n",
    "                job_title = job.find(name='a', attrs={'data-tn-element':'jobTitle'})\n",
    "                company = job.find(name='span', attrs={'class':'company'})\n",
    "                location = job.find(name='span', attrs={'class':'location'})\n",
    "                summary = job.find(name='span', attrs={'class':'summary'})\n",
    "                salary = job.find(name='span', attrs={'class':'no-wrap'})\n",
    "\n",
    "                # Put default for missing variables\n",
    "                if job_title != None:\n",
    "                    job_title_result = job_title.get_text()\n",
    "                    job_title_result = job_title_result.replace('\\n','')\n",
    "                    job_title_result = job_title_result.strip()\n",
    "                else:\n",
    "                    job_title_result = np.nan\n",
    "\n",
    "                if company != None:\n",
    "                    company_result = company.get_text()\n",
    "                    company_result = company_result.replace('\\n','')\n",
    "                    company_result = company_result.strip()\n",
    "                else:\n",
    "                    company_result = np.nan\n",
    "\n",
    "                if location != None:\n",
    "                    location_result = location.get_text()\n",
    "                    location_result = location_result.replace('\\n','')\n",
    "                    location_result = location_result.strip()\n",
    "                else:\n",
    "                    location_result = np.nan\n",
    "\n",
    "                if summary != None:\n",
    "                    summary_result = summary.get_text()\n",
    "                    summary_result = summary_result.replace('\\n','')\n",
    "                    summary_result = summary_result.strip()\n",
    "                else:\n",
    "                    summary_result = np.nan\n",
    "\n",
    "                if salary != None:\n",
    "\n",
    "                    salary_result = salary.get_text()\n",
    "                    salary_result = salary_result.replace('\\n','')\n",
    "                    salary_result = salary_result.strip()\n",
    "                else:\n",
    "                    salary_result = np.nan\n",
    "\n",
    "                # Append to list\n",
    "                job_category = '_'.join([word for word in query.split()])\n",
    "                jobs_list.append([job_category,job_title_result, company_result, location_result, summary_result, salary_result])\n",
    "\n",
    "# Convert jobs list to dataframe\n",
    "df = pd.DataFrame(jobs_list, columns = columns)\n",
    "# drop all duplicated job postings based on summary\n",
    "df.drop_duplicates(subset=['summary'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"DS_Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>job_category</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>indeed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>significant prior success as a data scientist ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>capita singapore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data scientist   data scientist needed to impr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>growth strategy  operations strategic planning...</td>\n",
       "      <td>wework</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ensuring data quality minimum  years of experi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>gateway search pte ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assess the effectiveness and accuracy of new d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientists  machine learning</td>\n",
       "      <td>biofourmis singapore</td>\n",
       "      <td>singapore</td>\n",
       "      <td>knowledge in big data technologies including c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist  aml group customer analytics  ...</td>\n",
       "      <td>ocbc bank</td>\n",
       "      <td>singapore</td>\n",
       "      <td>data scientist  aml group customer analytics  ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data engineer data science</td>\n",
       "      <td>twitter</td>\n",
       "      <td>singapore</td>\n",
       "      <td>data engineers work alongside data scientists ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>zyllem</td>\n",
       "      <td>singapore</td>\n",
       "      <td>interpreting data analyzing results using stat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>lenddoefl</td>\n",
       "      <td>singapore</td>\n",
       "      <td>proven experience in data manipulation as a da...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>cxa group pte. limited</td>\n",
       "      <td>singapore</td>\n",
       "      <td>leverage data visualization techniques and too...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>mr data scientist  local enterprise  central</td>\n",
       "      <td>jobally pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>experienced in identifying accessing and data ...</td>\n",
       "      <td>$8,000 - $10,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist  remote ok</td>\n",
       "      <td>indorse.io</td>\n",
       "      <td>singapore</td>\n",
       "      <td>as a data scientist you will be responsible fo...</td>\n",
       "      <td>$10,000 - $15,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>optimization data scientist  local enterprise ...</td>\n",
       "      <td>jobally pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>cloud based big data platform work with cloud ...</td>\n",
       "      <td>$8,000 - $10,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>basis</td>\n",
       "      <td>singapore</td>\n",
       "      <td>experience with etl and implementing efficient...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>pan-united corporation ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>design and qualifying processes for gathering ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist bank central up to k</td>\n",
       "      <td>kelly services singapore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interested candidates kindly submit your updat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data science lead large customer sales</td>\n",
       "      <td>google</td>\n",
       "      <td>singapore</td>\n",
       "      <td>as a data science lead you will generate actio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>operation data scientist  local enterprise  ce...</td>\n",
       "      <td>jobally pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>minimum  years of experience as data scientist...</td>\n",
       "      <td>$8,000 - $10,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist global data innovation centre</td>\n",
       "      <td>dentsu aegis</td>\n",
       "      <td>singapore</td>\n",
       "      <td>data scientist global data innovation centre a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>cisco careers</td>\n",
       "      <td>singapore</td>\n",
       "      <td>as a data scientist you will experience with d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data science senior manager</td>\n",
       "      <td>dell</td>\n",
       "      <td>central singapore</td>\n",
       "      <td>sql data modeling data warehousing concept  sd...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>dow technologies and systems</td>\n",
       "      <td>singapore</td>\n",
       "      <td>design efficient scalable automated processes ...</td>\n",
       "      <td>$5,500 - $8,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>dell</td>\n",
       "      <td>central singapore</td>\n",
       "      <td>we cant wait for you to discover this for your...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist  fast growing startup</td>\n",
       "      <td>lomotif</td>\n",
       "      <td>singapore</td>\n",
       "      <td>ability to conduct data mining processing clea...</td>\n",
       "      <td>$3,000 - $6,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>embedded data scientist</td>\n",
       "      <td>biofourmis</td>\n",
       "      <td>singapore</td>\n",
       "      <td>responsibilities  develop and implement embedd...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>ntuc enterprise nexus co-operative limited</td>\n",
       "      <td>singapore</td>\n",
       "      <td>you will be proficient in the application of a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>validus capital</td>\n",
       "      <td>raffles</td>\n",
       "      <td>work with data sets residing in different data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>xcellink pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>experience with data processing and data analy...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>junior data scientist</td>\n",
       "      <td>transferto</td>\n",
       "      <td>singapore</td>\n",
       "      <td>the data science  data engineering department ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>axinan pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>work with backend engineers to architect data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>698</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Quality Data Analyst/West/5days/Up to $3,500</td>\n",
       "      <td>Forte Employment Services Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Assist operation side to do data analysisof ke...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>699</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Asia Lead Gas Analyst - ICIS - Singapore</td>\n",
       "      <td>Reed Business Information</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>ICIS is looking for a Asia Lead Gas analyst to...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>700</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Salesforce Senior Consultant</td>\n",
       "      <td>CLOUDGO PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Understanding of relational databases includin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>701</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>System Analyst</td>\n",
       "      <td>KRIS INFOTECH PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Prepare test data, test scripts and test coded...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>702</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Hiring for Techno Functional Business Analyst ...</td>\n",
       "      <td>Aryan Search Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Exposure to Data Modelling techniques. We are ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>703</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Staff Business Analyst SAP Production Planning</td>\n",
       "      <td>Illumina</td>\n",
       "      <td>Woodlands</td>\n",
       "      <td>Work with global team to define conversion rul...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>704</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Senior IT Support Analyst (Legal Sector)</td>\n",
       "      <td>Ambition Group Singapore Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Data provided is for recruitment purposes only...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>705</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>AVP, Digital Analytics Analyst / Architect, Co...</td>\n",
       "      <td>DBS Bank</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Minimum 8 years’ experience in analytics or co...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>706</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Data Science Lead Consultant</td>\n",
       "      <td>CPM CONSULTING PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Proven experience (5+Years) as a Data Scientis...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>707</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Market Risk Analyst</td>\n",
       "      <td>Ambition</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Data provided is for recruitment purposes only...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>708</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>DotNet Developer</td>\n",
       "      <td>XPLORE INFOCOMZ SOLUTION (PTE. LTD.)</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Design, develop, test, and implement applicati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>709</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Senior Sales Operations Analyst</td>\n",
       "      <td>ServiceSource</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Senior Analyst will provide data in an informa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>710</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Business Analyst (Risk)</td>\n",
       "      <td>Sciente Consulting Pte. Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Knowledge on data governance process. Setup of...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>711</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Infrastructure Tech Arch Senior Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Work with data center team to resolve issues o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>712</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Lead Business Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Designing and reviewing data migration process...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>713</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>AVP, Business Analytics Analyst (Payments Team...</td>\n",
       "      <td>DBS Bank</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Work with various teams to design, develop and...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>714</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>Michael Page</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Supporting the building of data models. You wi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>715</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Content Coordinator</td>\n",
       "      <td>ONE ANIMATION PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Able to identify, analyze, and interpret trend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>716</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>IT Business Analyst - Fixed Income, Equities</td>\n",
       "      <td>BLUECHIP PLATFORMS ASIA PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Relevant experience in data science preferred....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>717</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Robert Walters</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>About the Business Analyst role:. To be succes...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>718</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Investment Analyst (Real Estate)</td>\n",
       "      <td>Tri-Cap Consulting Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Prepare industry, market and asset level data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>CRM Analyst</td>\n",
       "      <td>Robert Walters</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>About the CRM Analyst role:. Custodian of cust...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>720</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>IT Application Support Analyst (ETRM/CTRM)</td>\n",
       "      <td>Ambition Group Singapore Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Data provided is for recruitment purposes only...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>721</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Tableau Data Analyst, APAC with an Ecommerce c...</td>\n",
       "      <td>Michael Page</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Specialisation:IT Data Analysis. In line with ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>722</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Sr Staff Business Analyst</td>\n",
       "      <td>GLOBALFOUNDRIES SINGAPORE PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Improve Data analytics for Sales Ops KPIs and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>723</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Automation Test Engineer / Analyst</td>\n",
       "      <td>R SYSTEMS (SINGAPORE) PTE LIMITED</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Coordinate with BAs for test cases/test data. ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>724</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Network Security Analyst</td>\n",
       "      <td>NTT DATA SERVICES SINGAPORE PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Roles &amp; Responsibilities CheckPoint Secure Pla...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>725</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Field Lead</td>\n",
       "      <td>Clearstate Pte. Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Field data quality assurance:. The primary tas...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>726</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>AVP / Senior Associate, Platform Technical Lea...</td>\n",
       "      <td>DBS Bank</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>MAS TRM, MiFID II, personal data protection, I...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>727</td>\n",
       "      <td>data_analyst</td>\n",
       "      <td>TECHNOLOGY LEAD CONSULTANT</td>\n",
       "      <td>VIRTUSA SINGAPORE PRIVATE LIMITED</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>The candidate should be motivated to work in r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4845 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    job_category  \\\n",
       "0             0  data_scientist   \n",
       "1             1  data_scientist   \n",
       "2             2  data_scientist   \n",
       "3             3  data_scientist   \n",
       "4             4  data_scientist   \n",
       "5             5  data_scientist   \n",
       "6             6  data_scientist   \n",
       "7             7  data_scientist   \n",
       "8             8  data_scientist   \n",
       "9             9  data_scientist   \n",
       "10           10  data_scientist   \n",
       "11           11  data_scientist   \n",
       "12           12  data_scientist   \n",
       "13           13  data_scientist   \n",
       "14           14  data_scientist   \n",
       "15           15  data_scientist   \n",
       "16           16  data_scientist   \n",
       "17           17  data_scientist   \n",
       "18           18  data_scientist   \n",
       "19           19  data_scientist   \n",
       "20           20  data_scientist   \n",
       "21           21  data_scientist   \n",
       "22           22  data_scientist   \n",
       "23           23  data_scientist   \n",
       "24           24  data_scientist   \n",
       "25           25  data_scientist   \n",
       "26           26  data_scientist   \n",
       "27           27  data_scientist   \n",
       "28           28  data_scientist   \n",
       "29           29  data_scientist   \n",
       "..          ...             ...   \n",
       "698         698    data_analyst   \n",
       "699         699    data_analyst   \n",
       "700         700    data_analyst   \n",
       "701         701    data_analyst   \n",
       "702         702    data_analyst   \n",
       "703         703    data_analyst   \n",
       "704         704    data_analyst   \n",
       "705         705    data_analyst   \n",
       "706         706    data_analyst   \n",
       "707         707    data_analyst   \n",
       "708         708    data_analyst   \n",
       "709         709    data_analyst   \n",
       "710         710    data_analyst   \n",
       "711         711    data_analyst   \n",
       "712         712    data_analyst   \n",
       "713         713    data_analyst   \n",
       "714         714    data_analyst   \n",
       "715         715    data_analyst   \n",
       "716         716    data_analyst   \n",
       "717         717    data_analyst   \n",
       "718         718    data_analyst   \n",
       "719         719    data_analyst   \n",
       "720         720    data_analyst   \n",
       "721         721    data_analyst   \n",
       "722         722    data_analyst   \n",
       "723         723    data_analyst   \n",
       "724         724    data_analyst   \n",
       "725         725    data_analyst   \n",
       "726         726    data_analyst   \n",
       "727         727    data_analyst   \n",
       "\n",
       "                                             job_title  \\\n",
       "0                                       data scientist   \n",
       "1                                       data scientist   \n",
       "2    growth strategy  operations strategic planning...   \n",
       "3                                       data scientist   \n",
       "4                    data scientists  machine learning   \n",
       "5    data scientist  aml group customer analytics  ...   \n",
       "6                           data engineer data science   \n",
       "7                                       data scientist   \n",
       "8                                       data scientist   \n",
       "9                                       data scientist   \n",
       "10        mr data scientist  local enterprise  central   \n",
       "11                           data scientist  remote ok   \n",
       "12   optimization data scientist  local enterprise ...   \n",
       "13                                      data scientist   \n",
       "14                                      data scientist   \n",
       "15                 data scientist bank central up to k   \n",
       "16              data science lead large customer sales   \n",
       "17   operation data scientist  local enterprise  ce...   \n",
       "18        data scientist global data innovation centre   \n",
       "19                                      data scientist   \n",
       "20                         data science senior manager   \n",
       "21                                      data scientist   \n",
       "22                                      data scientist   \n",
       "23                data scientist  fast growing startup   \n",
       "24                             embedded data scientist   \n",
       "25                                      data scientist   \n",
       "26                                      data scientist   \n",
       "27                                      data scientist   \n",
       "28                               junior data scientist   \n",
       "29                                      data scientist   \n",
       "..                                                 ...   \n",
       "698       Quality Data Analyst/West/5days/Up to $3,500   \n",
       "699           Asia Lead Gas Analyst - ICIS - Singapore   \n",
       "700                       Salesforce Senior Consultant   \n",
       "701                                     System Analyst   \n",
       "702  Hiring for Techno Functional Business Analyst ...   \n",
       "703     Staff Business Analyst SAP Production Planning   \n",
       "704           Senior IT Support Analyst (Legal Sector)   \n",
       "705  AVP, Digital Analytics Analyst / Architect, Co...   \n",
       "706                       Data Science Lead Consultant   \n",
       "707                                Market Risk Analyst   \n",
       "708                                   DotNet Developer   \n",
       "709                    Senior Sales Operations Analyst   \n",
       "710                            Business Analyst (Risk)   \n",
       "711            Infrastructure Tech Arch Senior Analyst   \n",
       "712                              Lead Business Analyst   \n",
       "713  AVP, Business Analytics Analyst (Payments Team...   \n",
       "714                      Business Intelligence Analyst   \n",
       "715                                Content Coordinator   \n",
       "716       IT Business Analyst - Fixed Income, Equities   \n",
       "717                                   Business Analyst   \n",
       "718                   Investment Analyst (Real Estate)   \n",
       "719                                        CRM Analyst   \n",
       "720         IT Application Support Analyst (ETRM/CTRM)   \n",
       "721  Tableau Data Analyst, APAC with an Ecommerce c...   \n",
       "722                          Sr Staff Business Analyst   \n",
       "723                 Automation Test Engineer / Analyst   \n",
       "724                           Network Security Analyst   \n",
       "725                                         Field Lead   \n",
       "726  AVP / Senior Associate, Platform Technical Lea...   \n",
       "727                         TECHNOLOGY LEAD CONSULTANT   \n",
       "\n",
       "                                   company_name           location  \\\n",
       "0                                        indeed                NaN   \n",
       "1                              capita singapore                NaN   \n",
       "2                                        wework                NaN   \n",
       "3                        gateway search pte ltd                NaN   \n",
       "4                          biofourmis singapore          singapore   \n",
       "5                                     ocbc bank          singapore   \n",
       "6                                       twitter          singapore   \n",
       "7                                        zyllem          singapore   \n",
       "8                                     lenddoefl          singapore   \n",
       "9                        cxa group pte. limited          singapore   \n",
       "10                              jobally pte ltd          singapore   \n",
       "11                                   indorse.io          singapore   \n",
       "12                              jobally pte ltd          singapore   \n",
       "13                                        basis          singapore   \n",
       "14                   pan-united corporation ltd                NaN   \n",
       "15                     kelly services singapore                NaN   \n",
       "16                                       google          singapore   \n",
       "17                              jobally pte ltd          singapore   \n",
       "18                                 dentsu aegis          singapore   \n",
       "19                                cisco careers          singapore   \n",
       "20                                         dell  central singapore   \n",
       "21                 dow technologies and systems          singapore   \n",
       "22                                         dell  central singapore   \n",
       "23                                      lomotif          singapore   \n",
       "24                                   biofourmis          singapore   \n",
       "25   ntuc enterprise nexus co-operative limited          singapore   \n",
       "26                              validus capital            raffles   \n",
       "27                             xcellink pte ltd          singapore   \n",
       "28                                   transferto          singapore   \n",
       "29                               axinan pte ltd          singapore   \n",
       "..                                          ...                ...   \n",
       "698           Forte Employment Services Pte Ltd          Singapore   \n",
       "699                   Reed Business Information          Singapore   \n",
       "700                           CLOUDGO PTE. LTD.          Singapore   \n",
       "701                     KRIS INFOTECH PTE. LTD.          Singapore   \n",
       "702                        Aryan Search Pte Ltd          Singapore   \n",
       "703                                    Illumina          Woodlands   \n",
       "704            Ambition Group Singapore Pte Ltd          Singapore   \n",
       "705                                    DBS Bank          Singapore   \n",
       "706                    CPM CONSULTING PTE. LTD.          Singapore   \n",
       "707                                    Ambition          Singapore   \n",
       "708        XPLORE INFOCOMZ SOLUTION (PTE. LTD.)          Singapore   \n",
       "709                               ServiceSource          Singapore   \n",
       "710                 Sciente Consulting Pte. Ltd          Singapore   \n",
       "711                                   Accenture          Singapore   \n",
       "712                                         NaN          Singapore   \n",
       "713                                    DBS Bank          Singapore   \n",
       "714                                Michael Page          Singapore   \n",
       "715                     ONE ANIMATION PTE. LTD.          Singapore   \n",
       "716           BLUECHIP PLATFORMS ASIA PTE. LTD.          Singapore   \n",
       "717                              Robert Walters          Singapore   \n",
       "718                  Tri-Cap Consulting Pte Ltd          Singapore   \n",
       "719                              Robert Walters          Singapore   \n",
       "720            Ambition Group Singapore Pte Ltd          Singapore   \n",
       "721                                Michael Page          Singapore   \n",
       "722         GLOBALFOUNDRIES SINGAPORE PTE. LTD.          Singapore   \n",
       "723           R SYSTEMS (SINGAPORE) PTE LIMITED          Singapore   \n",
       "724       NTT DATA SERVICES SINGAPORE PTE. LTD.          Singapore   \n",
       "725                         Clearstate Pte. Ltd          Singapore   \n",
       "726                                    DBS Bank          Singapore   \n",
       "727           VIRTUSA SINGAPORE PRIVATE LIMITED          Singapore   \n",
       "\n",
       "                                               summary  \\\n",
       "0    significant prior success as a data scientist ...   \n",
       "1    data scientist   data scientist needed to impr...   \n",
       "2    ensuring data quality minimum  years of experi...   \n",
       "3    assess the effectiveness and accuracy of new d...   \n",
       "4    knowledge in big data technologies including c...   \n",
       "5    data scientist  aml group customer analytics  ...   \n",
       "6    data engineers work alongside data scientists ...   \n",
       "7    interpreting data analyzing results using stat...   \n",
       "8    proven experience in data manipulation as a da...   \n",
       "9    leverage data visualization techniques and too...   \n",
       "10   experienced in identifying accessing and data ...   \n",
       "11   as a data scientist you will be responsible fo...   \n",
       "12   cloud based big data platform work with cloud ...   \n",
       "13   experience with etl and implementing efficient...   \n",
       "14   design and qualifying processes for gathering ...   \n",
       "15   interested candidates kindly submit your updat...   \n",
       "16   as a data science lead you will generate actio...   \n",
       "17   minimum  years of experience as data scientist...   \n",
       "18   data scientist global data innovation centre a...   \n",
       "19   as a data scientist you will experience with d...   \n",
       "20   sql data modeling data warehousing concept  sd...   \n",
       "21   design efficient scalable automated processes ...   \n",
       "22   we cant wait for you to discover this for your...   \n",
       "23   ability to conduct data mining processing clea...   \n",
       "24   responsibilities  develop and implement embedd...   \n",
       "25   you will be proficient in the application of a...   \n",
       "26   work with data sets residing in different data...   \n",
       "27   experience with data processing and data analy...   \n",
       "28   the data science  data engineering department ...   \n",
       "29   work with backend engineers to architect data ...   \n",
       "..                                                 ...   \n",
       "698  Assist operation side to do data analysisof ke...   \n",
       "699  ICIS is looking for a Asia Lead Gas analyst to...   \n",
       "700  Understanding of relational databases includin...   \n",
       "701  Prepare test data, test scripts and test coded...   \n",
       "702  Exposure to Data Modelling techniques. We are ...   \n",
       "703  Work with global team to define conversion rul...   \n",
       "704  Data provided is for recruitment purposes only...   \n",
       "705  Minimum 8 years’ experience in analytics or co...   \n",
       "706  Proven experience (5+Years) as a Data Scientis...   \n",
       "707  Data provided is for recruitment purposes only...   \n",
       "708  Design, develop, test, and implement applicati...   \n",
       "709  Senior Analyst will provide data in an informa...   \n",
       "710  Knowledge on data governance process. Setup of...   \n",
       "711  Work with data center team to resolve issues o...   \n",
       "712  Designing and reviewing data migration process...   \n",
       "713  Work with various teams to design, develop and...   \n",
       "714  Supporting the building of data models. You wi...   \n",
       "715  Able to identify, analyze, and interpret trend...   \n",
       "716  Relevant experience in data science preferred....   \n",
       "717  About the Business Analyst role:. To be succes...   \n",
       "718  Prepare industry, market and asset level data ...   \n",
       "719  About the CRM Analyst role:. Custodian of cust...   \n",
       "720  Data provided is for recruitment purposes only...   \n",
       "721  Specialisation:IT Data Analysis. In line with ...   \n",
       "722  Improve Data analytics for Sales Ops KPIs and ...   \n",
       "723  Coordinate with BAs for test cases/test data. ...   \n",
       "724  Roles & Responsibilities CheckPoint Secure Pla...   \n",
       "725  Field data quality assurance:. The primary tas...   \n",
       "726  MAS TRM, MiFID II, personal data protection, I...   \n",
       "727  The candidate should be motivated to work in r...   \n",
       "\n",
       "                        salary  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "5                          NaN  \n",
       "6                          NaN  \n",
       "7                          NaN  \n",
       "8                          NaN  \n",
       "9                          NaN  \n",
       "10    $8,000 - $10,000 a month  \n",
       "11   $10,000 - $15,000 a month  \n",
       "12    $8,000 - $10,000 a month  \n",
       "13                         NaN  \n",
       "14                         NaN  \n",
       "15                         NaN  \n",
       "16                         NaN  \n",
       "17    $8,000 - $10,000 a month  \n",
       "18                         NaN  \n",
       "19                         NaN  \n",
       "20                         NaN  \n",
       "21     $5,500 - $8,000 a month  \n",
       "22                         NaN  \n",
       "23     $3,000 - $6,000 a month  \n",
       "24                         NaN  \n",
       "25                         NaN  \n",
       "26                         NaN  \n",
       "27                         NaN  \n",
       "28                         NaN  \n",
       "29                         NaN  \n",
       "..                         ...  \n",
       "698                        NaN  \n",
       "699                        NaN  \n",
       "700                        NaN  \n",
       "701                        NaN  \n",
       "702                        NaN  \n",
       "703                        NaN  \n",
       "704                        NaN  \n",
       "705                        NaN  \n",
       "706                        NaN  \n",
       "707                        NaN  \n",
       "708                        NaN  \n",
       "709                        NaN  \n",
       "710                        NaN  \n",
       "711                        NaN  \n",
       "712                        NaN  \n",
       "713                        NaN  \n",
       "714                        NaN  \n",
       "715                        NaN  \n",
       "716                        NaN  \n",
       "717                        NaN  \n",
       "718                        NaN  \n",
       "719                        NaN  \n",
       "720                        NaN  \n",
       "721                        NaN  \n",
       "722                        NaN  \n",
       "723                        NaN  \n",
       "724                        NaN  \n",
       "725                        NaN  \n",
       "726                        NaN  \n",
       "727                        NaN  \n",
       "\n",
       "[4845 rows x 7 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For some reason when I tried do to multiple searches, it always returned me the error on top. Couldn't solve it in time.\n",
    "# So i just opened 3x terminals and doing each category of search, saving them into CSV, then concat the DF together\n",
    "df0 = pd.read_csv(\"DS_Search\")\n",
    "df1 = pd.read_csv(\"BA_Search\")\n",
    "df2 = pd.read_csv(\"DA_Search\")\n",
    "df = pd.concat([df0, df1, df2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['summary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3341 entries, 0 to 3340\n",
      "Data columns (total 6 columns):\n",
      "job_category    3341 non-null object\n",
      "job_title       3341 non-null object\n",
      "company_name    3306 non-null object\n",
      "location        3303 non-null object\n",
      "summary         3341 non-null object\n",
      "salary          122 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 156.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_cleaned_combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_category</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>indeed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>significant prior success as a data scientist ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>capita singapore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data scientist   data scientist needed to impr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>growth strategy  operations strategic planning...</td>\n",
       "      <td>wework</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ensuring data quality minimum  years of experi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>gateway search pte ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assess the effectiveness and accuracy of new d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientists  machine learning</td>\n",
       "      <td>biofourmis singapore</td>\n",
       "      <td>singapore</td>\n",
       "      <td>knowledge in big data technologies including c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist  aml group customer analytics  ...</td>\n",
       "      <td>ocbc bank</td>\n",
       "      <td>singapore</td>\n",
       "      <td>data scientist  aml group customer analytics  ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data engineer data science</td>\n",
       "      <td>twitter</td>\n",
       "      <td>singapore</td>\n",
       "      <td>data engineers work alongside data scientists ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>zyllem</td>\n",
       "      <td>singapore</td>\n",
       "      <td>interpreting data analyzing results using stat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>lenddoefl</td>\n",
       "      <td>singapore</td>\n",
       "      <td>proven experience in data manipulation as a da...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>cxa group pte. limited</td>\n",
       "      <td>singapore</td>\n",
       "      <td>leverage data visualization techniques and too...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>mr data scientist  local enterprise  central</td>\n",
       "      <td>jobally pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>experienced in identifying accessing and data ...</td>\n",
       "      <td>$8,000 - $10,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist  remote ok</td>\n",
       "      <td>indorse.io</td>\n",
       "      <td>singapore</td>\n",
       "      <td>as a data scientist you will be responsible fo...</td>\n",
       "      <td>$10,000 - $15,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>optimization data scientist  local enterprise ...</td>\n",
       "      <td>jobally pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>cloud based big data platform work with cloud ...</td>\n",
       "      <td>$8,000 - $10,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>basis</td>\n",
       "      <td>singapore</td>\n",
       "      <td>experience with etl and implementing efficient...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>pan-united corporation ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>design and qualifying processes for gathering ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist bank central up to k</td>\n",
       "      <td>kelly services singapore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interested candidates kindly submit your updat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data science lead large customer sales</td>\n",
       "      <td>google</td>\n",
       "      <td>singapore</td>\n",
       "      <td>as a data science lead you will generate actio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>operation data scientist  local enterprise  ce...</td>\n",
       "      <td>jobally pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>minimum  years of experience as data scientist...</td>\n",
       "      <td>$8,000 - $10,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist global data innovation centre</td>\n",
       "      <td>dentsu aegis</td>\n",
       "      <td>singapore</td>\n",
       "      <td>data scientist global data innovation centre a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>cisco careers</td>\n",
       "      <td>singapore</td>\n",
       "      <td>as a data scientist you will experience with d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data science senior manager</td>\n",
       "      <td>dell</td>\n",
       "      <td>central singapore</td>\n",
       "      <td>sql data modeling data warehousing concept  sd...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>dow technologies and systems</td>\n",
       "      <td>singapore</td>\n",
       "      <td>design efficient scalable automated processes ...</td>\n",
       "      <td>$5,500 - $8,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>dell</td>\n",
       "      <td>central singapore</td>\n",
       "      <td>we cant wait for you to discover this for your...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist  fast growing startup</td>\n",
       "      <td>lomotif</td>\n",
       "      <td>singapore</td>\n",
       "      <td>ability to conduct data mining processing clea...</td>\n",
       "      <td>$3,000 - $6,000 a month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>embedded data scientist</td>\n",
       "      <td>biofourmis</td>\n",
       "      <td>singapore</td>\n",
       "      <td>responsibilities  develop and implement embedd...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>ntuc enterprise nexus co-operative limited</td>\n",
       "      <td>singapore</td>\n",
       "      <td>you will be proficient in the application of a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>validus capital</td>\n",
       "      <td>raffles</td>\n",
       "      <td>work with data sets residing in different data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>xcellink pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>experience with data processing and data analy...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>junior data scientist</td>\n",
       "      <td>transferto</td>\n",
       "      <td>singapore</td>\n",
       "      <td>the data science  data engineering department ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data_scientist</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>axinan pte ltd</td>\n",
       "      <td>singapore</td>\n",
       "      <td>work with backend engineers to architect data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Quality Data Analyst/West/5days/Up to $3,500</td>\n",
       "      <td>Forte Employment Services Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Assist operation side to do data analysisof ke...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Asia Lead Gas Analyst - ICIS - Singapore</td>\n",
       "      <td>Reed Business Information</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>ICIS is looking for a Asia Lead Gas analyst to...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Salesforce Senior Consultant</td>\n",
       "      <td>CLOUDGO PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Understanding of relational databases includin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>System Analyst</td>\n",
       "      <td>KRIS INFOTECH PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Prepare test data, test scripts and test coded...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Hiring for Techno Functional Business Analyst ...</td>\n",
       "      <td>Aryan Search Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Exposure to Data Modelling techniques. We are ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Staff Business Analyst SAP Production Planning</td>\n",
       "      <td>Illumina</td>\n",
       "      <td>Woodlands</td>\n",
       "      <td>Work with global team to define conversion rul...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Senior IT Support Analyst (Legal Sector)</td>\n",
       "      <td>Ambition Group Singapore Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Data provided is for recruitment purposes only...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>AVP, Digital Analytics Analyst / Architect, Co...</td>\n",
       "      <td>DBS Bank</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Minimum 8 years’ experience in analytics or co...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Data Science Lead Consultant</td>\n",
       "      <td>CPM CONSULTING PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Proven experience (5+Years) as a Data Scientis...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Market Risk Analyst</td>\n",
       "      <td>Ambition</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Data provided is for recruitment purposes only...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>DotNet Developer</td>\n",
       "      <td>XPLORE INFOCOMZ SOLUTION (PTE. LTD.)</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Design, develop, test, and implement applicati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Senior Sales Operations Analyst</td>\n",
       "      <td>ServiceSource</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Senior Analyst will provide data in an informa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Business Analyst (Risk)</td>\n",
       "      <td>Sciente Consulting Pte. Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Knowledge on data governance process. Setup of...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Infrastructure Tech Arch Senior Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Work with data center team to resolve issues o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Lead Business Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Designing and reviewing data migration process...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>AVP, Business Analytics Analyst (Payments Team...</td>\n",
       "      <td>DBS Bank</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Work with various teams to design, develop and...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>Michael Page</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Supporting the building of data models. You wi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Content Coordinator</td>\n",
       "      <td>ONE ANIMATION PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Able to identify, analyze, and interpret trend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>IT Business Analyst - Fixed Income, Equities</td>\n",
       "      <td>BLUECHIP PLATFORMS ASIA PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Relevant experience in data science preferred....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Robert Walters</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>About the Business Analyst role:. To be succes...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Investment Analyst (Real Estate)</td>\n",
       "      <td>Tri-Cap Consulting Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Prepare industry, market and asset level data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>CRM Analyst</td>\n",
       "      <td>Robert Walters</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>About the CRM Analyst role:. Custodian of cust...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>IT Application Support Analyst (ETRM/CTRM)</td>\n",
       "      <td>Ambition Group Singapore Pte Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Data provided is for recruitment purposes only...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Tableau Data Analyst, APAC with an Ecommerce c...</td>\n",
       "      <td>Michael Page</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Specialisation:IT Data Analysis. In line with ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Sr Staff Business Analyst</td>\n",
       "      <td>GLOBALFOUNDRIES SINGAPORE PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Improve Data analytics for Sales Ops KPIs and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Automation Test Engineer / Analyst</td>\n",
       "      <td>R SYSTEMS (SINGAPORE) PTE LIMITED</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Coordinate with BAs for test cases/test data. ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Network Security Analyst</td>\n",
       "      <td>NTT DATA SERVICES SINGAPORE PTE. LTD.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Roles &amp; Responsibilities CheckPoint Secure Pla...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>Field Lead</td>\n",
       "      <td>Clearstate Pte. Ltd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Field data quality assurance:. The primary tas...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>AVP / Senior Associate, Platform Technical Lea...</td>\n",
       "      <td>DBS Bank</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>MAS TRM, MiFID II, personal data protection, I...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>TECHNOLOGY LEAD CONSULTANT</td>\n",
       "      <td>VIRTUSA SINGAPORE PRIVATE LIMITED</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>The candidate should be motivated to work in r...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3341 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_category                                          job_title  \\\n",
       "0     data_scientist                                     data scientist   \n",
       "1     data_scientist                                     data scientist   \n",
       "2     data_scientist  growth strategy  operations strategic planning...   \n",
       "3     data_scientist                                     data scientist   \n",
       "4     data_scientist                  data scientists  machine learning   \n",
       "5     data_scientist  data scientist  aml group customer analytics  ...   \n",
       "6     data_scientist                         data engineer data science   \n",
       "7     data_scientist                                     data scientist   \n",
       "8     data_scientist                                     data scientist   \n",
       "9     data_scientist                                     data scientist   \n",
       "10    data_scientist       mr data scientist  local enterprise  central   \n",
       "11    data_scientist                          data scientist  remote ok   \n",
       "12    data_scientist  optimization data scientist  local enterprise ...   \n",
       "13    data_scientist                                     data scientist   \n",
       "14    data_scientist                                     data scientist   \n",
       "15    data_scientist                data scientist bank central up to k   \n",
       "16    data_scientist             data science lead large customer sales   \n",
       "17    data_scientist  operation data scientist  local enterprise  ce...   \n",
       "18    data_scientist       data scientist global data innovation centre   \n",
       "19    data_scientist                                     data scientist   \n",
       "20    data_scientist                        data science senior manager   \n",
       "21    data_scientist                                     data scientist   \n",
       "22    data_scientist                                     data scientist   \n",
       "23    data_scientist               data scientist  fast growing startup   \n",
       "24    data_scientist                            embedded data scientist   \n",
       "25    data_scientist                                     data scientist   \n",
       "26    data_scientist                                     data scientist   \n",
       "27    data_scientist                                     data scientist   \n",
       "28    data_scientist                              junior data scientist   \n",
       "29    data_scientist                                     data scientist   \n",
       "...              ...                                                ...   \n",
       "3311    data_analyst       Quality Data Analyst/West/5days/Up to $3,500   \n",
       "3312    data_analyst           Asia Lead Gas Analyst - ICIS - Singapore   \n",
       "3313    data_analyst                       Salesforce Senior Consultant   \n",
       "3314    data_analyst                                     System Analyst   \n",
       "3315    data_analyst  Hiring for Techno Functional Business Analyst ...   \n",
       "3316    data_analyst     Staff Business Analyst SAP Production Planning   \n",
       "3317    data_analyst           Senior IT Support Analyst (Legal Sector)   \n",
       "3318    data_analyst  AVP, Digital Analytics Analyst / Architect, Co...   \n",
       "3319    data_analyst                       Data Science Lead Consultant   \n",
       "3320    data_analyst                                Market Risk Analyst   \n",
       "3321    data_analyst                                   DotNet Developer   \n",
       "3322    data_analyst                    Senior Sales Operations Analyst   \n",
       "3323    data_analyst                            Business Analyst (Risk)   \n",
       "3324    data_analyst            Infrastructure Tech Arch Senior Analyst   \n",
       "3325    data_analyst                              Lead Business Analyst   \n",
       "3326    data_analyst  AVP, Business Analytics Analyst (Payments Team...   \n",
       "3327    data_analyst                      Business Intelligence Analyst   \n",
       "3328    data_analyst                                Content Coordinator   \n",
       "3329    data_analyst       IT Business Analyst - Fixed Income, Equities   \n",
       "3330    data_analyst                                   Business Analyst   \n",
       "3331    data_analyst                   Investment Analyst (Real Estate)   \n",
       "3332    data_analyst                                        CRM Analyst   \n",
       "3333    data_analyst         IT Application Support Analyst (ETRM/CTRM)   \n",
       "3334    data_analyst  Tableau Data Analyst, APAC with an Ecommerce c...   \n",
       "3335    data_analyst                          Sr Staff Business Analyst   \n",
       "3336    data_analyst                 Automation Test Engineer / Analyst   \n",
       "3337    data_analyst                           Network Security Analyst   \n",
       "3338    data_analyst                                         Field Lead   \n",
       "3339    data_analyst  AVP / Senior Associate, Platform Technical Lea...   \n",
       "3340    data_analyst                         TECHNOLOGY LEAD CONSULTANT   \n",
       "\n",
       "                                    company_name           location  \\\n",
       "0                                         indeed                NaN   \n",
       "1                               capita singapore                NaN   \n",
       "2                                         wework                NaN   \n",
       "3                         gateway search pte ltd                NaN   \n",
       "4                           biofourmis singapore          singapore   \n",
       "5                                      ocbc bank          singapore   \n",
       "6                                        twitter          singapore   \n",
       "7                                         zyllem          singapore   \n",
       "8                                      lenddoefl          singapore   \n",
       "9                         cxa group pte. limited          singapore   \n",
       "10                               jobally pte ltd          singapore   \n",
       "11                                    indorse.io          singapore   \n",
       "12                               jobally pte ltd          singapore   \n",
       "13                                         basis          singapore   \n",
       "14                    pan-united corporation ltd                NaN   \n",
       "15                      kelly services singapore                NaN   \n",
       "16                                        google          singapore   \n",
       "17                               jobally pte ltd          singapore   \n",
       "18                                  dentsu aegis          singapore   \n",
       "19                                 cisco careers          singapore   \n",
       "20                                          dell  central singapore   \n",
       "21                  dow technologies and systems          singapore   \n",
       "22                                          dell  central singapore   \n",
       "23                                       lomotif          singapore   \n",
       "24                                    biofourmis          singapore   \n",
       "25    ntuc enterprise nexus co-operative limited          singapore   \n",
       "26                               validus capital            raffles   \n",
       "27                              xcellink pte ltd          singapore   \n",
       "28                                    transferto          singapore   \n",
       "29                                axinan pte ltd          singapore   \n",
       "...                                          ...                ...   \n",
       "3311           Forte Employment Services Pte Ltd          Singapore   \n",
       "3312                   Reed Business Information          Singapore   \n",
       "3313                           CLOUDGO PTE. LTD.          Singapore   \n",
       "3314                     KRIS INFOTECH PTE. LTD.          Singapore   \n",
       "3315                        Aryan Search Pte Ltd          Singapore   \n",
       "3316                                    Illumina          Woodlands   \n",
       "3317            Ambition Group Singapore Pte Ltd          Singapore   \n",
       "3318                                    DBS Bank          Singapore   \n",
       "3319                    CPM CONSULTING PTE. LTD.          Singapore   \n",
       "3320                                    Ambition          Singapore   \n",
       "3321        XPLORE INFOCOMZ SOLUTION (PTE. LTD.)          Singapore   \n",
       "3322                               ServiceSource          Singapore   \n",
       "3323                 Sciente Consulting Pte. Ltd          Singapore   \n",
       "3324                                   Accenture          Singapore   \n",
       "3325                                         NaN          Singapore   \n",
       "3326                                    DBS Bank          Singapore   \n",
       "3327                                Michael Page          Singapore   \n",
       "3328                     ONE ANIMATION PTE. LTD.          Singapore   \n",
       "3329           BLUECHIP PLATFORMS ASIA PTE. LTD.          Singapore   \n",
       "3330                              Robert Walters          Singapore   \n",
       "3331                  Tri-Cap Consulting Pte Ltd          Singapore   \n",
       "3332                              Robert Walters          Singapore   \n",
       "3333            Ambition Group Singapore Pte Ltd          Singapore   \n",
       "3334                                Michael Page          Singapore   \n",
       "3335         GLOBALFOUNDRIES SINGAPORE PTE. LTD.          Singapore   \n",
       "3336           R SYSTEMS (SINGAPORE) PTE LIMITED          Singapore   \n",
       "3337       NTT DATA SERVICES SINGAPORE PTE. LTD.          Singapore   \n",
       "3338                         Clearstate Pte. Ltd          Singapore   \n",
       "3339                                    DBS Bank          Singapore   \n",
       "3340           VIRTUSA SINGAPORE PRIVATE LIMITED          Singapore   \n",
       "\n",
       "                                                summary  \\\n",
       "0     significant prior success as a data scientist ...   \n",
       "1     data scientist   data scientist needed to impr...   \n",
       "2     ensuring data quality minimum  years of experi...   \n",
       "3     assess the effectiveness and accuracy of new d...   \n",
       "4     knowledge in big data technologies including c...   \n",
       "5     data scientist  aml group customer analytics  ...   \n",
       "6     data engineers work alongside data scientists ...   \n",
       "7     interpreting data analyzing results using stat...   \n",
       "8     proven experience in data manipulation as a da...   \n",
       "9     leverage data visualization techniques and too...   \n",
       "10    experienced in identifying accessing and data ...   \n",
       "11    as a data scientist you will be responsible fo...   \n",
       "12    cloud based big data platform work with cloud ...   \n",
       "13    experience with etl and implementing efficient...   \n",
       "14    design and qualifying processes for gathering ...   \n",
       "15    interested candidates kindly submit your updat...   \n",
       "16    as a data science lead you will generate actio...   \n",
       "17    minimum  years of experience as data scientist...   \n",
       "18    data scientist global data innovation centre a...   \n",
       "19    as a data scientist you will experience with d...   \n",
       "20    sql data modeling data warehousing concept  sd...   \n",
       "21    design efficient scalable automated processes ...   \n",
       "22    we cant wait for you to discover this for your...   \n",
       "23    ability to conduct data mining processing clea...   \n",
       "24    responsibilities  develop and implement embedd...   \n",
       "25    you will be proficient in the application of a...   \n",
       "26    work with data sets residing in different data...   \n",
       "27    experience with data processing and data analy...   \n",
       "28    the data science  data engineering department ...   \n",
       "29    work with backend engineers to architect data ...   \n",
       "...                                                 ...   \n",
       "3311  Assist operation side to do data analysisof ke...   \n",
       "3312  ICIS is looking for a Asia Lead Gas analyst to...   \n",
       "3313  Understanding of relational databases includin...   \n",
       "3314  Prepare test data, test scripts and test coded...   \n",
       "3315  Exposure to Data Modelling techniques. We are ...   \n",
       "3316  Work with global team to define conversion rul...   \n",
       "3317  Data provided is for recruitment purposes only...   \n",
       "3318  Minimum 8 years’ experience in analytics or co...   \n",
       "3319  Proven experience (5+Years) as a Data Scientis...   \n",
       "3320  Data provided is for recruitment purposes only...   \n",
       "3321  Design, develop, test, and implement applicati...   \n",
       "3322  Senior Analyst will provide data in an informa...   \n",
       "3323  Knowledge on data governance process. Setup of...   \n",
       "3324  Work with data center team to resolve issues o...   \n",
       "3325  Designing and reviewing data migration process...   \n",
       "3326  Work with various teams to design, develop and...   \n",
       "3327  Supporting the building of data models. You wi...   \n",
       "3328  Able to identify, analyze, and interpret trend...   \n",
       "3329  Relevant experience in data science preferred....   \n",
       "3330  About the Business Analyst role:. To be succes...   \n",
       "3331  Prepare industry, market and asset level data ...   \n",
       "3332  About the CRM Analyst role:. Custodian of cust...   \n",
       "3333  Data provided is for recruitment purposes only...   \n",
       "3334  Specialisation:IT Data Analysis. In line with ...   \n",
       "3335  Improve Data analytics for Sales Ops KPIs and ...   \n",
       "3336  Coordinate with BAs for test cases/test data. ...   \n",
       "3337  Roles & Responsibilities CheckPoint Secure Pla...   \n",
       "3338  Field data quality assurance:. The primary tas...   \n",
       "3339  MAS TRM, MiFID II, personal data protection, I...   \n",
       "3340  The candidate should be motivated to work in r...   \n",
       "\n",
       "                         salary  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                           NaN  \n",
       "3                           NaN  \n",
       "4                           NaN  \n",
       "5                           NaN  \n",
       "6                           NaN  \n",
       "7                           NaN  \n",
       "8                           NaN  \n",
       "9                           NaN  \n",
       "10     $8,000 - $10,000 a month  \n",
       "11    $10,000 - $15,000 a month  \n",
       "12     $8,000 - $10,000 a month  \n",
       "13                          NaN  \n",
       "14                          NaN  \n",
       "15                          NaN  \n",
       "16                          NaN  \n",
       "17     $8,000 - $10,000 a month  \n",
       "18                          NaN  \n",
       "19                          NaN  \n",
       "20                          NaN  \n",
       "21      $5,500 - $8,000 a month  \n",
       "22                          NaN  \n",
       "23      $3,000 - $6,000 a month  \n",
       "24                          NaN  \n",
       "25                          NaN  \n",
       "26                          NaN  \n",
       "27                          NaN  \n",
       "28                          NaN  \n",
       "29                          NaN  \n",
       "...                         ...  \n",
       "3311                        NaN  \n",
       "3312                        NaN  \n",
       "3313                        NaN  \n",
       "3314                        NaN  \n",
       "3315                        NaN  \n",
       "3316                        NaN  \n",
       "3317                        NaN  \n",
       "3318                        NaN  \n",
       "3319                        NaN  \n",
       "3320                        NaN  \n",
       "3321                        NaN  \n",
       "3322                        NaN  \n",
       "3323                        NaN  \n",
       "3324                        NaN  \n",
       "3325                        NaN  \n",
       "3326                        NaN  \n",
       "3327                        NaN  \n",
       "3328                        NaN  \n",
       "3329                        NaN  \n",
       "3330                        NaN  \n",
       "3331                        NaN  \n",
       "3332                        NaN  \n",
       "3333                        NaN  \n",
       "3334                        NaN  \n",
       "3335                        NaN  \n",
       "3336                        NaN  \n",
       "3337                        NaN  \n",
       "3338                        NaN  \n",
       "3339                        NaN  \n",
       "3340                        NaN  \n",
       "\n",
       "[3341 rows x 6 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all null values except for salary\n",
    "df.dropna(subset=['company_name','summary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all to small letters if string\n",
    "df = df.applymap(lambda x: x.lower().strip() if isinstance(x, str) else x)\n",
    "# remove all non-alphabets\n",
    "df.job_title = df.job_title.map(lambda x: re.sub(r'[^A-Za-z\\s]','',x).strip())\n",
    "df.summary = df.summary.map(lambda x: re.sub(r'[^A-Za-z\\s]','',x).strip())\n",
    "# remove business licence numbers\n",
    "df.company_name = df.company_name.map(lambda x: x[:x.index(', ea licence')] if x.find(', ea licence') != -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter jobs by data related terms\n",
    "data_terms = ['data','analytics','intelligence','analysis','statistics','machine learning']\n",
    "df_summary_null = df.summary.map(lambda x: x if any(x.find(t)>=0 for t in data_terms) else np.nan).isnull()\n",
    "df_job_title_null = df.job_title.map(lambda x: x if any(x.find(t)>=0 for t in data_terms) else np.nan).isnull()\n",
    "df_mod = df[(~df_summary_null) | (~df_job_title_null)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88 entries, 10 to 3309\n",
      "Data columns (total 6 columns):\n",
      "job_category    88 non-null object\n",
      "job_title       88 non-null object\n",
      "company_name    88 non-null object\n",
      "location        88 non-null object\n",
      "summary         88 non-null object\n",
      "salary          88 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Well, looks like people just don't want to put salary. For the sake of time (and my sanity), I'll just use it. \n",
    "# If I had a chance to, I'd probably see if I can find more data on this.\n",
    "\n",
    "df_mod[~df_mod.salary.isnull()].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract those without salary data\n",
    "df_unsalaried = df_mod[df_mod.salary.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract those with salary data\n",
    "df_salaried = df_mod[~df_mod.salary.isnull()]\n",
    "df_salaried.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all salary into yearly format\n",
    "salary_range = df_salaried.salary.map(lambda x: re.sub('[^0-9\\s]', '', ' '.join(re.findall(r'\\d+(?:[\\d,.]*\\d)', x))))\n",
    "salary_period = df_salaried.salary.map(lambda x: x[x.find('month'):] if x.find('month') >= 0 else x[x.find('hour'):] if x.find('hour') >= 0 else 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_sal = []\n",
    "\n",
    "for i in range(0, len(salary_period)):\n",
    "    if salary_period.loc[i] == 'month':\n",
    "        sal = int(salary_range[i].split()[0])\n",
    "        temp_sal.append(sal*12)\n",
    "    elif salary_period.loc[i] == 'hour':\n",
    "        sal = int(salary_range[i].split()[0])\n",
    "        temp_sal.append(sal*2080)\n",
    "    else:\n",
    "        temp_sal.append(int(salary_range[i].split()[0]))\n",
    "\n",
    "salary_annual = pd.DataFrame(temp_sal, columns=['salary_annual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_annual = pd.DataFrame(temp_sal, columns=['salary_annual'])\n",
    "# Classifiy Salary into high, low tier\n",
    "salary_high_tier = salary_annual.applymap(lambda x: 1 if x > int(salary_annual.median()) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayden\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_salaried.drop(labels=['salary'], axis=1, inplace=True)\n",
    "df_salaried_mod = pd.concat([df_salaried, salary_high_tier], axis=1)\n",
    "df_salaried_mod.rename(index=str, columns={'salary_annual': 'salary_high_tier'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88 entries, 0 to 87\n",
      "Data columns (total 6 columns):\n",
      "job_category        88 non-null object\n",
      "job_title           88 non-null object\n",
      "company_name        88 non-null object\n",
      "location            88 non-null object\n",
      "summary             88 non-null object\n",
      "salary_high_tier    88 non-null int64\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# We will use those jobs with description to predict those without\n",
    "df_salaried_mod.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "1. Get TFIDF of job title, company, location, summary\n",
    "\n",
    "2. Use data with salary to predict those without\n",
    "\n",
    "3. Find out features with highest significant in distinguishing high vs low salary jobs\n",
    "\n",
    "4. Then collect TFIDF again for whole dataset and do second round of modelling\n",
    "\n",
    "5. Check to see whether top features are the same with round 1\n",
    "\n",
    "6. Features that appear highly significant in both rounds are the factors that are best at distinguishing high vs low salary\n",
    "\n",
    "7. For my study, i will generate features from my dataset using TFIDF\n",
    "\n",
    "8. Will use log reg and decision tree to predict, unless results really bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get TFIDF for job summary\n",
    "job_summary_tvec = TfidfVectorizer(ngram_range=(1,3), stop_words='english', min_df=2, max_df=0.5, max_features=25)\n",
    "job_summary_tvec.fit(df_salaried_mod.summary)\n",
    "job_summary_tvec_df = pd.DataFrame(job_summary_tvec.transform(df_salaried_mod.summary).todense(),\n",
    "                       columns=['summary_[' + f + ']' for f in job_summary_tvec.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF for job title\n",
    "job_title_tvec = TfidfVectorizer(ngram_range=(1,3), stop_words='english', min_df=2, max_df=0.5, max_features=25)\n",
    "job_title_tvec.fit(df_salaried_mod.job_title)\n",
    "job_title_tvec_df = pd.DataFrame(job_title_tvec.transform(df_salaried_mod.summary).todense(),\n",
    "                       columns=['title_[' + f + ']' for f in job_title_tvec.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF for company name\n",
    "job_company_tvec = TfidfVectorizer(ngram_range=(1,3), stop_words='english', min_df=2, max_df=0.5, max_features=25)\n",
    "job_company_tvec.fit(df_salaried_mod.company_name)\n",
    "job_company_tvec_df = pd.DataFrame(job_company_tvec.transform(df_salaried_mod.company_name).todense(),\n",
    "                       columns=['company_[' + f + ']' for f in job_company_tvec.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_with_sal = df_salaried_mod.salary_high_tier\n",
    "X_with_sal = pd.concat([job_summary_tvec_df,job_title_tvec_df,job_company_tvec_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_sal, y_with_sal, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize predictors\n",
    "X_train_ss = StandardScaler().fit_transform(X_train)\n",
    "X_test_ss = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss = pd.DataFrame(X_train_ss, columns=X_train.columns)\n",
    "X_test_ss = pd.DataFrame(X_test_ss, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit with plain logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.62      0.74        16\n",
      "          1       0.62      0.91      0.74        11\n",
      "\n",
      "avg / total       0.79      0.74      0.74        27\n",
      "\n",
      "f1-score: 0.7407407407407406\n"
     ]
    }
   ],
   "source": [
    "pred = lr.predict(X_test_ss)\n",
    "score = metrics.f1_score(y_test, pred)\n",
    "print(classification_report(y_test, pred))\n",
    "print('f1-score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH:\n",
      "Best parameters set:\n",
      "\tC: 0.08697490026177834\n",
      "\tpenalty: 'l2'\n",
      "\tsolver: 'liblinear'\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch for Ridge and Lasso Logistic Regression, optimize C\n",
    "\n",
    "parameters = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}\n",
    "\n",
    "print (\"GRID SEARCH:\")\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), parameters, cv=10, verbose=0)\n",
    "lr_grid_search.fit(X_train_ss, y_train)\n",
    "print (\"Best parameters set:\")\n",
    "lr_best_parameters = lr_grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print (\"\\t%s: %r\" % (param_name, lr_best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with best parameter:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "high salary       0.59      0.91      0.71        11\n",
      " low salary       0.90      0.56      0.69        16\n",
      "\n",
      "avg / total       0.77      0.70      0.70        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Logistic Regression with best parameter:\")\n",
    "clf = LogisticRegression(**lr_best_parameters)\n",
    "clf.fit(X_train_ss, y_train)\n",
    "lr_gs_pred = clf.predict(X_test_ss)\n",
    "print(metrics.classification_report(y_test, lr_gs_pred, labels=[1,0], target_names=['high salary','low salary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch params\n",
    "dtc_params = {\n",
    "    'max_depth':[None,1,2,3,4],\n",
    "    'max_features':[None,'log2','sqrt',2,3,4,5],\n",
    "    'min_samples_split':[2,3,4,5,10,15,20,25,30,40,50]\n",
    "}\n",
    "\n",
    "# set the gridsearch\n",
    "dtc_gs = GridSearchCV(DecisionTreeClassifier(), dtc_params, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 385 candidates, totalling 1925 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1925 out of 1925 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [None, 1, 2, 3, 4], 'max_features': [None, 'log2', 'sqrt', 2, 3, 4, 5], 'min_samples_split': [2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the gridsearch C model to fit the data\n",
    "dtc_gs.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': 4, 'min_samples_split': 3}\n",
      "0.8852459016393442\n"
     ]
    }
   ],
   "source": [
    "# Best Estimator\n",
    "dtc_best = dtc_gs.best_estimator_\n",
    "print(dtc_gs.best_params_)\n",
    "print(dtc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>summary_[insights]</td>\n",
       "      <td>0.120376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>title_[data]</td>\n",
       "      <td>0.117584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>summary_[working]</td>\n",
       "      <td>0.094951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>summary_[using]</td>\n",
       "      <td>0.078879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summary_[analysts]</td>\n",
       "      <td>0.067611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>summary_[team]</td>\n",
       "      <td>0.065733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>summary_[requirements]</td>\n",
       "      <td>0.061147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>company_[systems]</td>\n",
       "      <td>0.057787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>title_[data analyst]</td>\n",
       "      <td>0.051404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>company_[pte]</td>\n",
       "      <td>0.043822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "11      summary_[insights]    0.120376\n",
       "32            title_[data]    0.117584\n",
       "24       summary_[working]    0.094951\n",
       "22         summary_[using]    0.078879\n",
       "2       summary_[analysts]    0.067611\n",
       "19          summary_[team]    0.065733\n",
       "15  summary_[requirements]    0.061147\n",
       "69       company_[systems]    0.057787\n",
       "33    title_[data analyst]    0.051404\n",
       "65           company_[pte]    0.043822"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature':X_train_ss.columns,\n",
    "        'importance':dtc_best.feature_importances_\n",
    "    })\n",
    "\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "fi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>mag</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.398748</td>\n",
       "      <td>0.398748</td>\n",
       "      <td>summary_[using]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.334503</td>\n",
       "      <td>0.334503</td>\n",
       "      <td>summary_[requirements]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.292206</td>\n",
       "      <td>0.292206</td>\n",
       "      <td>summary_[analysts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.269633</td>\n",
       "      <td>0.269633</td>\n",
       "      <td>summary_[team]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.221801</td>\n",
       "      <td>0.221801</td>\n",
       "      <td>summary_[analysis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.214737</td>\n",
       "      <td>0.214737</td>\n",
       "      <td>summary_[role]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.201654</td>\n",
       "      <td>0.201654</td>\n",
       "      <td>summary_[insights]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.196832</td>\n",
       "      <td>0.196832</td>\n",
       "      <td>summary_[skills]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.165080</td>\n",
       "      <td>0.165080</td>\n",
       "      <td>company_[tvconal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.160385</td>\n",
       "      <td>0.160385</td>\n",
       "      <td>company_[ninja]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef       mag                    pred\n",
       "22 -0.398748  0.398748         summary_[using]\n",
       "15 -0.334503  0.334503  summary_[requirements]\n",
       "2  -0.292206  0.292206      summary_[analysts]\n",
       "19 -0.269633  0.269633          summary_[team]\n",
       "0   0.221801  0.221801      summary_[analysis]\n",
       "16 -0.214737  0.214737          summary_[role]\n",
       "11 -0.201654  0.201654      summary_[insights]\n",
       "17 -0.196832  0.196832        summary_[skills]\n",
       "74 -0.165080  0.165080       company_[tvconal]\n",
       "62 -0.160385  0.160385         company_[ninja]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = lr_grid_search.best_estimator_.coef_\n",
    "lr_coef = pd.DataFrame({'coef':coef.ravel(),\n",
    "                    'mag':np.abs(coef.ravel()),\n",
    "                    'pred':X_test_ss.columns})\n",
    "\n",
    "lr_coef.sort_values('mag', ascending=False, inplace=True)\n",
    "lr_coef.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "high salary       0.67      0.73      0.70        11\n",
      " low salary       0.80      0.75      0.77        16\n",
      "\n",
      "avg / total       0.75      0.74      0.74        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = dtc_best.predict(X_test_ss)\n",
    "print(classification_report(y_test, pred, labels=[1,0], target_names=['high salary','low salary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree has a better score than log reg\n",
    "# Will take Decision Tree as model to evaluate factors that impact salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2016 entries, 0 to 3340\n",
      "Data columns (total 6 columns):\n",
      "job_category    2016 non-null object\n",
      "job_title       2016 non-null object\n",
      "company_name    2016 non-null object\n",
      "location        1990 non-null object\n",
      "summary         2016 non-null object\n",
      "salary          0 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 110.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Use decision tree to predict the rest of the dataset\n",
    "df_unsalaried.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF for job title\n",
    "job_title_tvec_unsal = TfidfVectorizer(ngram_range=(1,3), stop_words='english', min_df=2, max_df=0.5, max_features=25)\n",
    "job_title_tvec_unsal.fit(df_unsalaried.job_title)\n",
    "job_title_tvec_unsal_df = pd.DataFrame(job_title_tvec_unsal.transform(df_unsalaried.job_title).todense(),\n",
    "                       columns=['title_[' + f + ']' for f in job_title_tvec_unsal.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF for job summary\n",
    "job_summary_tvec_unsal = TfidfVectorizer(ngram_range=(1,3), stop_words='english', min_df=2, max_df=0.5, max_features=25)\n",
    "job_summary_tvec_unsal.fit(df_unsalaried.summary)\n",
    "job_summary_tvec_unsal_df = pd.DataFrame(job_summary_tvec_unsal.transform(df_unsalaried.summary).todense(),\n",
    "                       columns=['summary_[' + f + ']' for f in job_summary_tvec_unsal.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF for company name\n",
    "job_company_tvec_unsal = TfidfVectorizer(ngram_range=(1,3), stop_words='english', min_df=2, max_df=0.5, max_features=25)\n",
    "job_company_tvec_unsal.fit(df_unsalaried.company_name)\n",
    "job_company_tvec_unsal_df = pd.DataFrame(job_company_tvec_unsal.transform(df_unsalaried.company_name).todense(),\n",
    "                       columns=['company_[' + f + ']' for f in job_company_tvec_unsal.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_without_sal = pd.concat([job_summary_tvec_unsal_df,job_title_tvec_unsal_df,job_company_tvec_unsal_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize predictors\n",
    "X_without_sal_ss = StandardScaler().fit_transform(X_without_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_without_sal_ss = pd.DataFrame(X_without_sal_ss, columns=X_without_sal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayden\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\ayden\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "pred = dtc_best.predict(X_without_sal_ss)\n",
    "df_unsalaried.salary = pred\n",
    "df_unsalaried.rename(index=str, columns={\"salary\": \"salary_high_tier\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge predicted with original\n",
    "final_df = pd.concat([df_unsalaried, df_salaried_mod], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF for job title\n",
    "job_title_tvec_final = TfidfVectorizer(ngram_range=(1,3), stop_words='english', min_df=2, max_df=0.5, max_features=25)\n",
    "job_title_tvec_final.fit(final_df.job_title)\n",
    "job_title_tvec_final_df = pd.DataFrame(job_title_tvec_final.transform(final_df.job_title).todense(),\n",
    "                       columns=['title_[' + f + ']' for f in job_title_tvec_final.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF for job summary\n",
    "job_summary_tvec_final = TfidfVectorizer(ngram_range=(1,3), stop_words='english', min_df=2, max_df=0.5, max_features=25)\n",
    "job_summary_tvec_final.fit(final_df.summary)\n",
    "job_summary_tvec_final_df = pd.DataFrame(job_summary_tvec_final.transform(final_df.summary).todense(),\n",
    "                       columns=['summary_[' + f + ']' for f in job_summary_tvec_final.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF for company name\n",
    "job_company_tvec_final = TfidfVectorizer(ngram_range=(1,3), stop_words='english', min_df=2, max_df=0.5, max_features=25)\n",
    "job_company_tvec_final.fit(final_df.company_name)\n",
    "job_company_tvec_final_df = pd.DataFrame(job_company_tvec_final.transform(final_df.company_name).todense(),\n",
    "                       columns=['company_[' + f + ']' for f in job_company_tvec_final.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([job_title_tvec_final_df, job_summary_tvec_final_df, job_company_tvec_final_df], axis=1)\n",
    "y = final_df.salary_high_tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize predictors\n",
    "Xs = StandardScaler().fit_transform(X)\n",
    "Xs = pd.DataFrame(Xs, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH:\n",
      "Best parameters set:\n",
      "\tC: 0.49770235643321137\n",
      "\tpenalty: 'l1'\n",
      "\tsolver: 'liblinear'\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch for Ridge and Lasso Logistic Regression, optimize C\n",
    "\n",
    "parameters = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}\n",
    "\n",
    "print (\"GRID SEARCH:\")\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), parameters, cv=10, verbose=0)\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "print (\"Best parameters set:\")\n",
    "lr_best_parameters = lr_grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print (\"\\t%s: %r\" % (param_name, lr_best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with best param:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "high salary       0.94      0.95      0.95       446\n",
      " low salary       0.91      0.90      0.90       249\n",
      "\n",
      "avg / total       0.93      0.93      0.93       695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with best param:\")\n",
    "clf = LogisticRegression(**lr_best_parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "lr_gs_pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, lr_gs_pred, labels=[1,0], target_names=['high salary','low salary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch params for decision tree classifier\n",
    "dtc_params = {\n",
    "    'max_depth':[None,1,2,3,4],\n",
    "    'max_features':[None,'log2','sqrt',2,3,4,5],\n",
    "    'min_samples_split':[2,3,4,5,10,15,20,25,30,40,50]\n",
    "}\n",
    "\n",
    "# set the gridsearch\n",
    "dtc_gs = GridSearchCV(DecisionTreeClassifier(), dtc_params, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 385 candidates, totalling 1925 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1925 out of 1925 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [None, 1, 2, 3, 4], 'max_features': [None, 'log2', 'sqrt', 2, 3, 4, 5], 'min_samples_split': [2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the gridsearch C model to fit the data\n",
    "dtc_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': None, 'min_samples_split': 2}\n",
      "0.9772888573456352\n"
     ]
    }
   ],
   "source": [
    "# Best Estimator\n",
    "dtc_best = dtc_gs.best_estimator_\n",
    "print(dtc_gs.best_params_)\n",
    "print(dtc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "high salary       0.98      0.98      0.98       446\n",
      " low salary       0.96      0.96      0.96       249\n",
      "\n",
      "avg / total       0.97      0.97      0.97       695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = dtc_best.predict(X_test)\n",
    "print(classification_report(y_test, pred, labels=[1,0], target_names=['high salary','low salary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>title_[data]</td>\n",
       "      <td>0.260233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>summary_[requirements]</td>\n",
       "      <td>0.130360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>summary_[years]</td>\n",
       "      <td>0.123791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>summary_[insights]</td>\n",
       "      <td>0.120150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>summary_[science]</td>\n",
       "      <td>0.108398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>company_[singapore pte]</td>\n",
       "      <td>0.107946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>summary_[working]</td>\n",
       "      <td>0.038830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>title_[engineer]</td>\n",
       "      <td>0.013765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>summary_[systems]</td>\n",
       "      <td>0.013444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>company_[pte]</td>\n",
       "      <td>0.012108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance\n",
       "7              title_[data]    0.260233\n",
       "40   summary_[requirements]    0.130360\n",
       "49          summary_[years]    0.123791\n",
       "36       summary_[insights]    0.120150\n",
       "42        summary_[science]    0.108398\n",
       "69  company_[singapore pte]    0.107946\n",
       "48        summary_[working]    0.038830\n",
       "11         title_[engineer]    0.013765\n",
       "45        summary_[systems]    0.013444\n",
       "65            company_[pte]    0.012108"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature':X_train.columns,\n",
    "        'importance':dtc_best.feature_importances_\n",
    "    })\n",
    "\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "fi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>mag</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-2.824296</td>\n",
       "      <td>2.824296</td>\n",
       "      <td>summary_[requirements]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-2.176361</td>\n",
       "      <td>2.176361</td>\n",
       "      <td>summary_[insights]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-1.993205</td>\n",
       "      <td>1.993205</td>\n",
       "      <td>summary_[years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.505648</td>\n",
       "      <td>1.505648</td>\n",
       "      <td>title_[data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-1.425915</td>\n",
       "      <td>1.425915</td>\n",
       "      <td>company_[singapore pte]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1.195753</td>\n",
       "      <td>1.195753</td>\n",
       "      <td>summary_[science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.844117</td>\n",
       "      <td>0.844117</td>\n",
       "      <td>summary_[working]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.835526</td>\n",
       "      <td>0.835526</td>\n",
       "      <td>title_[data analyst]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.594279</td>\n",
       "      <td>0.594279</td>\n",
       "      <td>title_[scientist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.486018</td>\n",
       "      <td>0.486018</td>\n",
       "      <td>company_[solutions pte]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef       mag                     pred\n",
       "40 -2.824296  2.824296   summary_[requirements]\n",
       "36 -2.176361  2.176361       summary_[insights]\n",
       "49 -1.993205  1.993205          summary_[years]\n",
       "7  -1.505648  1.505648             title_[data]\n",
       "69 -1.425915  1.425915  company_[singapore pte]\n",
       "42 -1.195753  1.195753        summary_[science]\n",
       "48  0.844117  0.844117        summary_[working]\n",
       "8  -0.835526  0.835526     title_[data analyst]\n",
       "20  0.594279  0.594279        title_[scientist]\n",
       "71  0.486018  0.486018  company_[solutions pte]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coef = pd.DataFrame({'coef':clf.coef_.ravel(),\n",
    "                    'mag':np.abs(clf.coef_.ravel()),\n",
    "                    'pred':X_test.columns})\n",
    "\n",
    "lr_coef.sort_values('mag', ascending=False, inplace=True)\n",
    "lr_coef.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the \"Top Factors\" that affect high salary vs low salary are mostly the same\n",
    "# Also, Decision Tree is the better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df for question 2\n",
    "final_df.to_csv('final_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
